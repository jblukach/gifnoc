Parameters:
  inputbucketname:
    Type: String
    Default: <input-bucket-name>
    Description: Input Bucket Name
  ouputbucketname:
    Type: String
    Default: <output-bucket-name>
    Description: Output Bucket Name
Resources:
  inputbucketNotifications10F8B3DA:
    Type: Custom::S3BucketNotifications
    Properties:
      ServiceToken:
        Fn::GetAtt:
          - BucketNotificationsHandler050a0587b7544547bf325f094a3db8347ECC3691
          - Arn
      BucketName:
        Ref: inputbucketname
      NotificationConfiguration:
        QueueConfigurations:
          - Events:
              - s3:ObjectCreated:*
            QueueArn:
              Fn::GetAtt:
                - queue276F7297
                - Arn
      Managed: false
      SkipDestinationValidation: false
    DependsOn:
      - queuePolicy89DB7105
      - queue276F7297
  queue276F7297:
    Type: AWS::SQS::Queue
    Properties:
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
      VisibilityTimeout: 900
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
  queuePolicy89DB7105:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Statement:
          - Action: sqs:SendMessage
            Condition:
              ArnLike:
                aws:SourceArn:
                  Fn::Join:
                    - ""
                    - - "arn:aws:s3:::"
                      - Ref: inputbucketname
            Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Resource:
              Fn::GetAtt:
                - queue276F7297
                - Arn
          - Action:
              - sqs:GetQueueAttributes
              - sqs:GetQueueUrl
              - sqs:SendMessage
            Condition:
              ArnLike:
                aws:SourceArn:
                  Fn::Join:
                    - ""
                    - - "arn:aws:s3:::"
                      - Ref: inputbucketname
            Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Resource:
              Fn::GetAtt:
                - queue276F7297
                - Arn
        Version: "2012-10-17"
      Queues:
        - Ref: queue276F7297
  BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
        Version: "2012-10-17"
      ManagedPolicyArns:
        - Fn::Join:
            - ""
            - - "arn:"
              - Ref: AWS::Partition
              - :iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
  BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action:
              - s3:GetBucketNotification
              - s3:PutBucketNotification
            Effect: Allow
            Resource: "*"
        Version: "2012-10-17"
      PolicyName: BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36
      Roles:
        - Ref: BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
  BucketNotificationsHandler050a0587b7544547bf325f094a3db8347ECC3691:
    Type: AWS::Lambda::Function
    Properties:
      Description: AWS CloudFormation handler for "Custom::S3BucketNotifications" resources (@aws-cdk/aws-s3)
      Code:
        ZipFile: |-
          import boto3  # type: ignore
          import json
          import logging
          import urllib.request

          s3 = boto3.client("s3")

          EVENTBRIDGE_CONFIGURATION = 'EventBridgeConfiguration'
          CONFIGURATION_TYPES = ["TopicConfigurations", "QueueConfigurations", "LambdaFunctionConfigurations"]

          def handler(event: dict, context):
            response_status = "SUCCESS"
            error_message = ""
            try:
              props = event["ResourceProperties"]
              notification_configuration = props["NotificationConfiguration"]
              managed = props.get('Managed', 'true').lower() == 'true'
              skipDestinationValidation = props.get('SkipDestinationValidation', 'false').lower() == 'true'
              stack_id = event['StackId']
              old = event.get("OldResourceProperties", {}).get("NotificationConfiguration", {})
              if managed:
                config = handle_managed(event["RequestType"], notification_configuration)
              else:
                config = handle_unmanaged(props["BucketName"], stack_id, event["RequestType"], notification_configuration, old)
              s3.put_bucket_notification_configuration(Bucket=props["BucketName"], NotificationConfiguration=config, SkipDestinationValidation=skipDestinationValidation)
            except Exception as e:
              logging.exception("Failed to put bucket notification configuration")
              response_status = "FAILED"
              error_message = f"Error: {str(e)}. "
            finally:
              submit_response(event, context, response_status, error_message)

          def handle_managed(request_type, notification_configuration):
            if request_type == 'Delete':
              return {}
            return notification_configuration

          def handle_unmanaged(bucket, stack_id, request_type, notification_configuration, old):
            def get_id(n):
              n['Id'] = ''
              sorted_notifications = sort_filter_rules(n)
              strToHash=json.dumps(sorted_notifications, sort_keys=True).replace('"Name": "prefix"', '"Name": "Prefix"').replace('"Name": "suffix"', '"Name": "Suffix"')
              return f"{stack_id}-{hash(strToHash)}"
            def with_id(n):
              n['Id'] = get_id(n)
              return n

            external_notifications = {}
            existing_notifications = s3.get_bucket_notification_configuration(Bucket=bucket)
            for t in CONFIGURATION_TYPES:
              if request_type == 'Update':
                  old_incoming_ids = [get_id(n) for n in old.get(t, [])]
                  external_notifications[t] = [n for n in existing_notifications.get(t, []) if not get_id(n) in old_incoming_ids]      
              elif request_type == 'Delete':
                  external_notifications[t] = [n for n in existing_notifications.get(t, []) if not n['Id'].startswith(f"{stack_id}-")]
              elif request_type == 'Create':
                  external_notifications[t] = [n for n in existing_notifications.get(t, [])]
            if EVENTBRIDGE_CONFIGURATION in existing_notifications:
              external_notifications[EVENTBRIDGE_CONFIGURATION] = existing_notifications[EVENTBRIDGE_CONFIGURATION]

            if request_type == 'Delete':
              return external_notifications

            notifications = {}
            for t in CONFIGURATION_TYPES:
              external = external_notifications.get(t, [])
              incoming = [with_id(n) for n in notification_configuration.get(t, [])]
              notifications[t] = external + incoming

            if EVENTBRIDGE_CONFIGURATION in notification_configuration:
              notifications[EVENTBRIDGE_CONFIGURATION] = notification_configuration[EVENTBRIDGE_CONFIGURATION]
            elif EVENTBRIDGE_CONFIGURATION in external_notifications:
              notifications[EVENTBRIDGE_CONFIGURATION] = external_notifications[EVENTBRIDGE_CONFIGURATION]

            return notifications

          def submit_response(event: dict, context, response_status: str, error_message: str):
            response_body = json.dumps(
              {
                "Status": response_status,
                "Reason": f"{error_message}See the details in CloudWatch Log Stream: {context.log_stream_name}",
                "PhysicalResourceId": event.get("PhysicalResourceId") or event["LogicalResourceId"],
                "StackId": event["StackId"],
                "RequestId": event["RequestId"],
                "LogicalResourceId": event["LogicalResourceId"],
                "NoEcho": False,
              }
            ).encode("utf-8")
            headers = {"content-type": "", "content-length": str(len(response_body))}
            try:
              req = urllib.request.Request(url=event["ResponseURL"], headers=headers, data=response_body, method="PUT")
              with urllib.request.urlopen(req) as response:
                print(response.read().decode("utf-8"))
              print("Status code: " + response.reason)
            except Exception as e:
                print("send(..) failed executing request.urlopen(..): " + str(e))

          def sort_filter_rules(json_obj):
            if not isinstance(json_obj, dict):
                return json_obj
            for key, value in json_obj.items():
                if isinstance(value, dict):
                    json_obj[key] = sort_filter_rules(value)
                elif isinstance(value, list):
                    json_obj[key] = [sort_filter_rules(item) for item in value]
            if "Filter" in json_obj and "Key" in json_obj["Filter"] and "FilterRules" in json_obj["Filter"]["Key"]:
                filter_rules = json_obj["Filter"]["Key"]["FilterRules"]
                sorted_filter_rules = sorted(filter_rules, key=lambda x: x["Name"])
                json_obj["Filter"]["Key"]["FilterRules"] = sorted_filter_rules
            return json_obj
      Handler: index.handler
      Role:
        Fn::GetAtt:
          - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
          - Arn
      Runtime: python3.11
      Timeout: 300
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
    DependsOn:
      - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36
      - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
  roleC7B7E775:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
        Version: "2012-10-17"
      ManagedPolicyArns:
        - Fn::Join:
            - ""
            - - "arn:"
              - Ref: AWS::Partition
              - :iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
  roleDefaultPolicy7C980EBA:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action: s3:GetObject
            Effect: Allow
            Resource:
              Fn::Join:
                - ""
                - - "arn:aws:s3:::"
                  - Ref: inputbucketname
                  - /*
          - Action: s3:PutObject
            Effect: Allow
            Resource:
              Fn::Join:
                - ""
                - - "arn:aws:s3:::"
                  - Ref: ouputbucketname
                  - /*
          - Action:
              - kms:Decrypt
              - kms:DescribeKey
              - kms:GenerateDataKey
            Effect: Allow
            Resource: "*"
          - Action:
              - sqs:ChangeMessageVisibility
              - sqs:DeleteMessage
              - sqs:GetQueueAttributes
              - sqs:GetQueueUrl
              - sqs:ReceiveMessage
            Effect: Allow
            Resource:
              Fn::GetAtt:
                - queue276F7297
                - Arn
        Version: "2012-10-17"
      PolicyName: roleDefaultPolicy7C980EBA
      Roles:
        - Ref: roleC7B7E775
  gifnoc64E13FCE:
    Type: AWS::Lambda::Function
    Properties:
      Architectures:
        - arm64
      Code:
        ZipFile: |-
          import boto3
          import gzip
          import json
          import os

          def handler(event, context):

              s3 = boto3.client('s3')

              for records in event['Records']:
                  j = json.loads(records['body'])
                  for record in j['Records']:
                      print(record['s3']['object']['key'])

                      if 'ConfigHistory' in record['s3']['object']['key']:
                          s3.download_file(os.environ['INPUT'], record['s3']['object']['key'], '/tmp/temp.json.gz')
                          with gzip.open('/tmp/temp.json.gz', 'rb') as f:
                              content = f.read().decode('utf-8')
                          f.close()
                          with gzip.open('/tmp/hold.json.gz', 'wb') as g:
                              j = json.loads(content)
                              for item in j['configurationItems']:
                                  temp = {}
                                  temp['fileVersion'] = j['fileVersion']
                                  temp['configurationItem'] = item
                                  g.write((str(temp)+str('\n')).encode())
                          g.close()
                          s3.upload_file('/tmp/hold.json.gz', os.environ['OUTPUT'], record['s3']['object']['key'])

                      if 'ConfigSnapshot' in record['s3']['object']['key']:
                          s3.download_file(os.environ['INPUT'], record['s3']['object']['key'], '/tmp/temp.json.gz')
                          with gzip.open('/tmp/temp.json.gz', 'rb') as f:
                              content = f.read().decode('utf-8')
                          f.close()
                          with gzip.open('/tmp/hold.json.gz', 'wb') as g:
                              j = json.loads(content)
                              for item in j['configurationItems']:
                                  temp = {}
                                  temp['fileVersion'] = j['fileVersion']
                                  temp['configSnapshotId'] = j['configSnapshotId']
                                  temp['configurationItem'] = item
                                  g.write((str(temp)+str('\n')).encode())
                          g.close()
                          s3.upload_file('/tmp/hold.json.gz', os.environ['OUTPUT'], record['s3']['object']['key'])

              return {
                  'statusCode': 200,
                  'body': json.dumps('Shipped!')
              }
      Environment:
        Variables:
          INPUT:
            Ref: inputbucketname
          OUTPUT:
            Ref: ouputbucketname
      Handler: index.handler
      MemorySize: 512
      Role:
        Fn::GetAtt:
          - roleC7B7E775
          - Arn
      Runtime: python3.13
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
      Timeout: 900
    DependsOn:
      - roleDefaultPolicy7C980EBA
      - roleC7B7E775
  gifnocSqsEventSourceGifnocStackqueue13F9BAEE5723F291:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      EventSourceArn:
        Fn::GetAtt:
          - queue276F7297
          - Arn
      FunctionName:
        Ref: gifnoc64E13FCE
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
  logs0B6081B1:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName:
        Fn::Join:
          - ""
          - - /aws/lambda/
            - Ref: gifnoc64E13FCE
      RetentionInDays: 14
      Tags:
        - Key: GitHub
          Value: https://github.com/jblukach/gifnoc
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete

